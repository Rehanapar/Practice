{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cee1e23-9419-4de1-8f5e-4e199894de93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1642 entries, 0 to 1641\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   model         1642 non-null   object \n",
      " 1   year          1642 non-null   int64  \n",
      " 2   motor_type    1642 non-null   object \n",
      " 3   running       1642 non-null   object \n",
      " 4   wheel         1642 non-null   object \n",
      " 5   color         1642 non-null   object \n",
      " 6   type          1642 non-null   object \n",
      " 7   status        1642 non-null   object \n",
      " 8   motor_volume  1642 non-null   float64\n",
      " 9   price         1642 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 128.4+ KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# Load train and test datasets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Checking information of the train data\n",
    "train_df.info()\n",
    "\n",
    "# Initialize LabelEncoder and dictionary to store encoders for each column\n",
    "label_encoders = {}\n",
    "\n",
    "# List of categorical columns to encode\n",
    "categorical_columns = ['model', 'motor_type', 'wheel', 'color', 'status', 'type']\n",
    "\n",
    "# Apply LabelEncoder to each categorical column for both train and test\n",
    "for col in categorical_columns:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    train_df[col] = label_encoders[col].fit_transform(train_df[col])\n",
    "    test_df[col] = test_df[col].apply(lambda x: label_encoders[col].transform([x])[0] if x in label_encoders[col].classes_ else -1)\n",
    "\n",
    "# Function to convert running values from 'km' to 'miles'\n",
    "def convert_running(value):\n",
    "    if 'km' in value:\n",
    "        kilometers = int(value.split()[0])\n",
    "        miles = kilometers * 0.621371\n",
    "        return f\"{miles:.2f} miles\"\n",
    "    elif 'miles' in value:\n",
    "        return value\n",
    "    else:\n",
    "        return value \n",
    "\n",
    "# Apply the conversion for both train and test datasets\n",
    "train_df['running'] = train_df['running'].apply(convert_running)\n",
    "test_df['running'] = test_df['running'].apply(convert_running)\n",
    "\n",
    "# Clean and convert 'running' column to numeric values\n",
    "train_df['running'] = train_df['running'].str.replace('miles', '').str.strip()\n",
    "test_df['running'] = test_df['running'].str.replace('miles', '').str.strip()\n",
    "train_df['running'] = pd.to_numeric(train_df['running'], errors='coerce').fillna(0).astype('int64')\n",
    "test_df['running'] = pd.to_numeric(test_df['running'], errors='coerce').fillna(0).astype('int64')\n",
    "\n",
    "# Drop duplicates from the training data\n",
    "train_df = train_df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74642ba2-79eb-4dc9-a223-14daa9a167c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare features and target variable\n",
    "X = train_df.drop(['price', 'wheel'], axis = 1) # Replace 'target_column' with your actual target column name\n",
    "y = train_df['price']  # Your target variable\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33f09d99-8905-49fb-b1ac-c0b41ebc849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(test_df.drop(columns=['Id', 'wheel']))  # Adjust as necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "906d26bf-05e1-46d9-97f6-fdca041251f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the deep learning model with improved architecture\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(1)  # Output layer for regression\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74fc88da-625d-4375-a75a-203936469467",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model with a learning rate scheduler\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "154ed765-201e-438c-aad6-172f8294bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit the model with early stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_mae', patience=10, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "371aab15-1f06-41df-943c-1bd071f6d40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 15975.6973 - mae: 15973.1016 - val_loss: 15867.6680 - val_mae: 15864.9561\n",
      "Epoch 2/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16153.4922 - mae: 16150.3291 - val_loss: 15109.6113 - val_mae: 15104.0869\n",
      "Epoch 3/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14095.8584 - mae: 14088.8828 - val_loss: 11207.1699 - val_mae: 11194.3516\n",
      "Epoch 4/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9044.6006 - mae: 9029.2041 - val_loss: 4077.6743 - val_mae: 4054.7783\n",
      "Epoch 5/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4338.5298 - mae: 4315.4819 - val_loss: 3622.4961 - val_mae: 3600.2366\n",
      "Epoch 6/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3872.0859 - mae: 3849.7834 - val_loss: 3399.0857 - val_mae: 3376.7224\n",
      "Epoch 7/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3426.2930 - mae: 3404.0198 - val_loss: 3254.9622 - val_mae: 3232.3992\n",
      "Epoch 8/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3564.5566 - mae: 3542.0002 - val_loss: 3158.7705 - val_mae: 3136.3076\n",
      "Epoch 9/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3380.7734 - mae: 3358.3801 - val_loss: 3121.1292 - val_mae: 3098.9009\n",
      "Epoch 10/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3354.1687 - mae: 3331.9526 - val_loss: 3059.3828 - val_mae: 3037.0076\n",
      "Epoch 11/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3376.0940 - mae: 3353.7334 - val_loss: 3108.4304 - val_mae: 3086.5779\n",
      "Epoch 12/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3286.1184 - mae: 3264.0750 - val_loss: 3097.4475 - val_mae: 3075.6140\n",
      "Epoch 13/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3239.7383 - mae: 3217.8733 - val_loss: 3016.6350 - val_mae: 2994.5815\n",
      "Epoch 14/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3490.3535 - mae: 3468.1875 - val_loss: 2991.9812 - val_mae: 2969.8875\n",
      "Epoch 15/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3236.3442 - mae: 3214.3228 - val_loss: 2985.5542 - val_mae: 2963.5332\n",
      "Epoch 16/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3116.2334 - mae: 3094.2295 - val_loss: 2998.7871 - val_mae: 2977.0049\n",
      "Epoch 17/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3462.7158 - mae: 3440.8501 - val_loss: 2966.5273 - val_mae: 2944.6582\n",
      "Epoch 18/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3363.8069 - mae: 3341.9919 - val_loss: 2966.6150 - val_mae: 2944.9512\n",
      "Epoch 19/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3237.5400 - mae: 3215.8423 - val_loss: 2980.1304 - val_mae: 2958.1233\n",
      "Epoch 20/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3185.1289 - mae: 3163.2563 - val_loss: 2948.0903 - val_mae: 2926.4661\n",
      "Epoch 21/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3179.9487 - mae: 3158.3052 - val_loss: 2950.3801 - val_mae: 2928.6238\n",
      "Epoch 22/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3151.5076 - mae: 3129.8022 - val_loss: 2940.4438 - val_mae: 2918.9573\n",
      "Epoch 23/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3249.4475 - mae: 3227.8723 - val_loss: 2938.3977 - val_mae: 2916.7817\n",
      "Epoch 24/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3255.9434 - mae: 3234.3130 - val_loss: 2973.9272 - val_mae: 2952.7600\n",
      "Epoch 25/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3082.4460 - mae: 3060.9932 - val_loss: 2930.8252 - val_mae: 2909.3640\n",
      "Epoch 26/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3278.5552 - mae: 3257.0740 - val_loss: 2923.5471 - val_mae: 2902.1926\n",
      "Epoch 27/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3210.3088 - mae: 3189.0229 - val_loss: 2922.3301 - val_mae: 2900.9277\n",
      "Epoch 28/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3019.9463 - mae: 2998.6709 - val_loss: 2914.3489 - val_mae: 2892.9558\n",
      "Epoch 29/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2933.5276 - mae: 2912.2698 - val_loss: 2908.8914 - val_mae: 2887.5281\n",
      "Epoch 30/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3356.2034 - mae: 3334.8906 - val_loss: 2908.2698 - val_mae: 2886.9375\n",
      "Epoch 31/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3103.2166 - mae: 3081.9788 - val_loss: 2901.8623 - val_mae: 2880.6855\n",
      "Epoch 32/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3083.5479 - mae: 3062.4619 - val_loss: 2899.0901 - val_mae: 2877.9089\n",
      "Epoch 33/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3246.3879 - mae: 3225.2600 - val_loss: 2905.7549 - val_mae: 2884.7063\n",
      "Epoch 34/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3094.2305 - mae: 3073.0552 - val_loss: 2898.3630 - val_mae: 2877.3218\n",
      "Epoch 35/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2966.4260 - mae: 2945.3857 - val_loss: 2893.4746 - val_mae: 2872.3894\n",
      "Epoch 36/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3072.8479 - mae: 3051.7878 - val_loss: 2890.3103 - val_mae: 2869.3025\n",
      "Epoch 37/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3056.3833 - mae: 3035.2761 - val_loss: 2895.2229 - val_mae: 2874.2686\n",
      "Epoch 38/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2949.4849 - mae: 2928.5635 - val_loss: 2912.0928 - val_mae: 2891.2957\n",
      "Epoch 39/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3106.0364 - mae: 3085.1460 - val_loss: 2897.5674 - val_mae: 2876.5691\n",
      "Epoch 40/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3120.4126 - mae: 3099.4561 - val_loss: 2902.4434 - val_mae: 2881.5110\n",
      "Epoch 41/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3077.1201 - mae: 3056.1282 - val_loss: 2900.9365 - val_mae: 2879.9978\n",
      "Epoch 42/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3050.4048 - mae: 3029.4998 - val_loss: 2921.4644 - val_mae: 2900.7910\n",
      "Epoch 43/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3250.9519 - mae: 3230.1851 - val_loss: 2888.6536 - val_mae: 2867.8899\n",
      "Epoch 44/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3160.4878 - mae: 3139.6973 - val_loss: 2893.5413 - val_mae: 2872.6465\n",
      "Epoch 45/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2880.1277 - mae: 2859.3225 - val_loss: 2885.4553 - val_mae: 2864.7612\n",
      "Epoch 46/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2945.2134 - mae: 2924.6057 - val_loss: 2899.2268 - val_mae: 2878.3694\n",
      "Epoch 47/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3111.8508 - mae: 3091.1062 - val_loss: 2880.0981 - val_mae: 2859.4678\n",
      "Epoch 48/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3075.3896 - mae: 3054.7341 - val_loss: 2898.4353 - val_mae: 2877.9512\n",
      "Epoch 49/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3013.6301 - mae: 2993.0566 - val_loss: 2888.4529 - val_mae: 2867.9170\n",
      "Epoch 50/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3079.9895 - mae: 3059.4756 - val_loss: 2899.0498 - val_mae: 2878.5391\n",
      "Epoch 51/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3113.7800 - mae: 3093.3230 - val_loss: 2882.0415 - val_mae: 2861.5112\n",
      "Epoch 52/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2960.3684 - mae: 2939.8193 - val_loss: 2879.6208 - val_mae: 2859.0056\n",
      "Epoch 53/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3108.9417 - mae: 3088.4558 - val_loss: 2877.8887 - val_mae: 2857.2322\n",
      "Epoch 54/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3086.9038 - mae: 3066.3350 - val_loss: 2900.4866 - val_mae: 2880.1709\n",
      "Epoch 55/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3097.4810 - mae: 3077.0415 - val_loss: 2884.9678 - val_mae: 2864.6594\n",
      "Epoch 56/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2961.5393 - mae: 2941.2676 - val_loss: 2892.1455 - val_mae: 2871.4907\n",
      "Epoch 57/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2955.6509 - mae: 2935.2720 - val_loss: 2869.0974 - val_mae: 2848.7073\n",
      "Epoch 58/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2986.3218 - mae: 2965.9377 - val_loss: 2884.7583 - val_mae: 2864.2893\n",
      "Epoch 59/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2961.1658 - mae: 2940.8315 - val_loss: 2875.8147 - val_mae: 2855.5601\n",
      "Epoch 60/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3065.6636 - mae: 3045.4082 - val_loss: 2872.4683 - val_mae: 2852.0845\n",
      "Epoch 61/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3082.9028 - mae: 3062.4905 - val_loss: 2893.5137 - val_mae: 2873.4075\n",
      "Epoch 62/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3091.5217 - mae: 3071.3489 - val_loss: 2918.7910 - val_mae: 2898.8367\n",
      "Epoch 63/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3012.0354 - mae: 2991.9724 - val_loss: 2879.9058 - val_mae: 2859.6602\n",
      "Epoch 64/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3257.6763 - mae: 3237.3784 - val_loss: 2872.8164 - val_mae: 2852.4626\n",
      "Epoch 65/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3084.1340 - mae: 3063.9712 - val_loss: 2884.2139 - val_mae: 2863.8799\n",
      "Epoch 66/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2987.9482 - mae: 2967.6304 - val_loss: 2886.7100 - val_mae: 2866.5037\n",
      "Epoch 67/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3318.4302 - mae: 3298.3191 - val_loss: 2878.9766 - val_mae: 2858.8032\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train_scaled, y_train, validation_data=(X_val_scaled, y_val), \n",
    "                    epochs=200, batch_size=32, callbacks=[early_stopping], verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cff643a5-0201-4d86-83d9-b0103dfe39f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2939.8088 - mae: 2919.4185\n",
      "Validation Mean Absolute Error: 2848.71\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "val_loss, val_mae = model.evaluate(X_val_scaled, y_val)\n",
    "print(f'Validation Mean Absolute Error: {val_mae:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fdc16c1-6acc-46fb-83a6-71637cc40214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions on the test set\n",
    "y_predict = model.predict(X_test_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "996cb035-deab-4fd8-a358-e31e77694d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            price\n",
      "0    18868.279297\n",
      "1    17014.986328\n",
      "2    18653.800781\n",
      "3    15579.852539\n",
      "4     7351.168457\n",
      "..            ...\n",
      "406  22412.291016\n",
      "407  13049.485352\n",
      "408   9771.448242\n",
      "409  17525.728516\n",
      "410  12831.936523\n",
      "\n",
      "[411 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for the predictions\n",
    "df_predictions = pd.DataFrame(y_predict, columns=['price'])\n",
    "\n",
    "# Display predictions\n",
    "print(df_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdcf64db-eca3-480b-9961-494e95aac107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18868.279297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17014.986328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18653.800781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15579.852539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7351.168457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>406</td>\n",
       "      <td>22412.291016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>407</td>\n",
       "      <td>13049.485352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>408</td>\n",
       "      <td>9771.448242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>409</td>\n",
       "      <td>17525.728516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>12831.936523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id         price\n",
       "0      0  18868.279297\n",
       "1      1  17014.986328\n",
       "2      2  18653.800781\n",
       "3      3  15579.852539\n",
       "4      4   7351.168457\n",
       "..   ...           ...\n",
       "406  406  22412.291016\n",
       "407  407  13049.485352\n",
       "408  408   9771.448242\n",
       "409  409  17525.728516\n",
       "410  410  12831.936523\n",
       "\n",
       "[411 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([test_df['Id'], df_predictions], axis=1)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9707188-4fb6-4a3c-896c-dcd0d24a82ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('piiiii.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bbf58a-ed4f-464c-9161-64b55e9c13e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
