{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d21905c3-79d1-45b4-9fbd-fee55d4d56b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1642 entries, 0 to 1641\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   model         1642 non-null   object \n",
      " 1   year          1642 non-null   int64  \n",
      " 2   motor_type    1642 non-null   object \n",
      " 3   running       1642 non-null   object \n",
      " 4   wheel         1642 non-null   object \n",
      " 5   color         1642 non-null   object \n",
      " 6   type          1642 non-null   object \n",
      " 7   status        1642 non-null   object \n",
      " 8   motor_volume  1642 non-null   float64\n",
      " 9   price         1642 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 128.4+ KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# Load train and test datasets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Checking information of the train data\n",
    "train_df.info()\n",
    "\n",
    "# Initialize LabelEncoder and dictionary to store encoders for each column\n",
    "label_encoders = {}\n",
    "\n",
    "# List of categorical columns to encode\n",
    "categorical_columns = ['model', 'motor_type', 'wheel', 'color', 'status', 'type']\n",
    "\n",
    "# Apply LabelEncoder to each categorical column for both train and test\n",
    "for col in categorical_columns:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    train_df[col] = label_encoders[col].fit_transform(train_df[col])\n",
    "    test_df[col] = test_df[col].apply(lambda x: label_encoders[col].transform([x])[0] if x in label_encoders[col].classes_ else -1)\n",
    "\n",
    "# Function to convert running values from 'km' to 'miles'\n",
    "def convert_running(value):\n",
    "    if 'km' in value:\n",
    "        kilometers = int(value.split()[0])\n",
    "        miles = kilometers * 0.621371\n",
    "        return f\"{miles:.2f} miles\"\n",
    "    elif 'miles' in value:\n",
    "        return value\n",
    "    else:\n",
    "        return value \n",
    "\n",
    "# Apply the conversion for both train and test datasets\n",
    "train_df['running'] = train_df['running'].apply(convert_running)\n",
    "test_df['running'] = test_df['running'].apply(convert_running)\n",
    "\n",
    "# Clean and convert 'running' column to numeric values\n",
    "train_df['running'] = train_df['running'].str.replace('miles', '').str.strip()\n",
    "test_df['running'] = test_df['running'].str.replace('miles', '').str.strip()\n",
    "train_df['running'] = pd.to_numeric(train_df['running'], errors='coerce').fillna(0).astype('int64')\n",
    "test_df['running'] = pd.to_numeric(test_df['running'], errors='coerce').fillna(0).astype('int64')\n",
    "\n",
    "# Drop duplicates from the training data\n",
    "train_df = train_df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4934a8f7-b216-4031-8057-fedd5e2d1ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare features and target variable\n",
    "X = train_df.drop(['price', 'wheel'], axis = 1) # Replace 'target_column' with your actual target column name\n",
    "y = train_df['price'] # Your target variable\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Create a DataFrame for the predictions\n",
    "# df_predictions = pd.DataFrame(y_predict, columns=['price'])\n",
    "\n",
    "# # Display predictions\n",
    "# print(df_predictions)\n",
    "\n",
    "# # Save predictions to a CSV file if needed\n",
    "# df_predictions.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40d4336a-48dd-401d-beab-c1a6fdfb9f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(test_df.drop(columns=['Id', 'wheel']))  # Adjust as necessary\n",
    "\n",
    "# Define the deep learning model with improved architecture\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79d497ae-3b4b-485e-83d5-fbe5328e82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with a learning rate scheduler\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0005)  # Adjusted learning rate\n",
    "model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85ba4af3-7063-4755-9c19-f19ada016c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit the model with early stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_mae', patience=10, restore_best_weights=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c132a86e-edf7-489b-af0e-152f25acbeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 15917.8662 - mae: 15917.2627 - val_loss: 15899.6240 - val_mae: 15899.0127\n",
      "Epoch 2/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16178.4189 - mae: 16177.7764 - val_loss: 15004.9951 - val_mae: 15004.1572\n",
      "Epoch 3/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13940.9199 - mae: 13939.9424 - val_loss: 7153.0664 - val_mae: 7151.5703\n",
      "Epoch 4/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5209.1235 - mae: 5207.5068 - val_loss: 3610.5884 - val_mae: 3608.9514\n",
      "Epoch 5/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3886.7302 - mae: 3885.0906 - val_loss: 3411.1809 - val_mae: 3409.5505\n",
      "Epoch 6/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3951.3967 - mae: 3949.7544 - val_loss: 3230.2603 - val_mae: 3228.6216\n",
      "Epoch 7/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3757.6924 - mae: 3756.0562 - val_loss: 3177.0181 - val_mae: 3175.3914\n",
      "Epoch 8/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3549.1479 - mae: 3547.5227 - val_loss: 3100.8191 - val_mae: 3099.1941\n",
      "Epoch 9/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3407.2942 - mae: 3405.6641 - val_loss: 3095.0974 - val_mae: 3093.4741\n",
      "Epoch 10/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3598.9141 - mae: 3597.2913 - val_loss: 3080.2778 - val_mae: 3078.6423\n",
      "Epoch 11/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3543.1582 - mae: 3541.5332 - val_loss: 3038.7476 - val_mae: 3037.1338\n",
      "Epoch 12/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3634.4839 - mae: 3632.8662 - val_loss: 3049.3042 - val_mae: 3047.6953\n",
      "Epoch 13/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3182.8335 - mae: 3181.2166 - val_loss: 3034.5173 - val_mae: 3032.9028\n",
      "Epoch 14/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3367.7476 - mae: 3366.1348 - val_loss: 3017.9563 - val_mae: 3016.3494\n",
      "Epoch 15/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3304.8931 - mae: 3303.2827 - val_loss: 3042.3923 - val_mae: 3040.7910\n",
      "Epoch 16/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3244.3052 - mae: 3242.7019 - val_loss: 3001.2944 - val_mae: 2999.6843\n",
      "Epoch 17/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3394.4868 - mae: 3392.8772 - val_loss: 3000.0315 - val_mae: 2998.4373\n",
      "Epoch 18/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3386.6655 - mae: 3385.0630 - val_loss: 2978.6692 - val_mae: 2977.0642\n",
      "Epoch 19/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3454.6780 - mae: 3453.0750 - val_loss: 2993.2742 - val_mae: 2991.6677\n",
      "Epoch 20/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3479.5701 - mae: 3477.9622 - val_loss: 3003.0576 - val_mae: 3001.4734\n",
      "Epoch 21/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3420.6741 - mae: 3419.0823 - val_loss: 2966.3525 - val_mae: 2964.7576\n",
      "Epoch 22/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3599.7473 - mae: 3598.1465 - val_loss: 3007.4001 - val_mae: 3005.8157\n",
      "Epoch 23/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3401.0737 - mae: 3399.4846 - val_loss: 2967.8540 - val_mae: 2966.2578\n",
      "Epoch 24/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3499.1287 - mae: 3497.5376 - val_loss: 2951.2561 - val_mae: 2949.6582\n",
      "Epoch 25/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3283.5281 - mae: 3281.9355 - val_loss: 2942.3120 - val_mae: 2940.7246\n",
      "Epoch 26/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3327.0100 - mae: 3325.4172 - val_loss: 2945.5574 - val_mae: 2943.9648\n",
      "Epoch 27/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3146.0798 - mae: 3144.4890 - val_loss: 2942.0081 - val_mae: 2940.4136\n",
      "Epoch 28/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3323.4910 - mae: 3321.8992 - val_loss: 2938.1753 - val_mae: 2936.5798\n",
      "Epoch 29/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3228.1316 - mae: 3226.5374 - val_loss: 2925.0112 - val_mae: 2923.4253\n",
      "Epoch 30/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3138.0383 - mae: 3136.4590 - val_loss: 2919.6990 - val_mae: 2918.1101\n",
      "Epoch 31/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3368.0745 - mae: 3366.4888 - val_loss: 2929.5386 - val_mae: 2927.9475\n",
      "Epoch 32/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3275.3899 - mae: 3273.8018 - val_loss: 2941.3987 - val_mae: 2939.8203\n",
      "Epoch 33/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3517.6438 - mae: 3516.0557 - val_loss: 2965.2866 - val_mae: 2963.7136\n",
      "Epoch 34/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3123.8616 - mae: 3122.2764 - val_loss: 2937.0347 - val_mae: 2935.4592\n",
      "Epoch 35/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3291.9219 - mae: 3290.3457 - val_loss: 2933.1101 - val_mae: 2931.5342\n",
      "Epoch 36/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3427.2085 - mae: 3425.6257 - val_loss: 2906.9167 - val_mae: 2905.3289\n",
      "Epoch 37/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3134.6851 - mae: 3133.1011 - val_loss: 2910.7715 - val_mae: 2909.1860\n",
      "Epoch 38/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3298.7688 - mae: 3297.1802 - val_loss: 2901.9653 - val_mae: 2900.3806\n",
      "Epoch 39/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3433.7905 - mae: 3432.2004 - val_loss: 2931.6650 - val_mae: 2930.0903\n",
      "Epoch 40/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3375.6584 - mae: 3374.0815 - val_loss: 2934.1865 - val_mae: 2932.6130\n",
      "Epoch 41/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3243.6165 - mae: 3242.0417 - val_loss: 2919.6599 - val_mae: 2918.0710\n",
      "Epoch 42/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3332.9563 - mae: 3331.3706 - val_loss: 2904.8684 - val_mae: 2903.2883\n",
      "Epoch 43/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3204.2136 - mae: 3202.6316 - val_loss: 2904.4224 - val_mae: 2902.8398\n",
      "Epoch 44/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3127.9316 - mae: 3126.3472 - val_loss: 2903.7373 - val_mae: 2902.1553\n",
      "Epoch 45/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3140.5967 - mae: 3139.0032 - val_loss: 2899.4058 - val_mae: 2897.8242\n",
      "Epoch 46/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3204.8147 - mae: 3203.2275 - val_loss: 2884.6116 - val_mae: 2883.0237\n",
      "Epoch 47/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3244.0447 - mae: 3242.4587 - val_loss: 2877.3320 - val_mae: 2875.7390\n",
      "Epoch 48/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3395.7388 - mae: 3394.1450 - val_loss: 2893.2769 - val_mae: 2891.6938\n",
      "Epoch 49/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3147.5337 - mae: 3145.9500 - val_loss: 2900.3560 - val_mae: 2898.7583\n",
      "Epoch 50/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3279.9988 - mae: 3278.4080 - val_loss: 2929.1650 - val_mae: 2927.5886\n",
      "Epoch 51/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3319.6628 - mae: 3318.0781 - val_loss: 2880.3333 - val_mae: 2878.7444\n",
      "Epoch 52/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3282.3416 - mae: 3280.7520 - val_loss: 2888.6941 - val_mae: 2887.1104\n",
      "Epoch 53/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3369.9214 - mae: 3368.3291 - val_loss: 2912.2510 - val_mae: 2910.6694\n",
      "Epoch 54/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3358.6636 - mae: 3357.0793 - val_loss: 2870.5496 - val_mae: 2868.9543\n",
      "Epoch 55/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3262.9456 - mae: 3261.3481 - val_loss: 2894.1379 - val_mae: 2892.5491\n",
      "Epoch 56/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3055.3042 - mae: 3053.7168 - val_loss: 2878.7778 - val_mae: 2877.1790\n",
      "Epoch 57/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3200.4900 - mae: 3198.8962 - val_loss: 2867.8948 - val_mae: 2866.3018\n",
      "Epoch 58/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3255.4907 - mae: 3253.8950 - val_loss: 2854.3689 - val_mae: 2852.7720\n",
      "Epoch 59/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3195.0979 - mae: 3193.5056 - val_loss: 2899.4270 - val_mae: 2897.8447\n",
      "Epoch 60/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3253.2317 - mae: 3251.6394 - val_loss: 2878.7236 - val_mae: 2877.1194\n",
      "Epoch 61/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3226.6113 - mae: 3225.0193 - val_loss: 2861.2874 - val_mae: 2859.6904\n",
      "Epoch 62/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3351.4185 - mae: 3349.8157 - val_loss: 2896.4468 - val_mae: 2894.8616\n",
      "Epoch 63/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3008.2029 - mae: 3006.6104 - val_loss: 2870.7017 - val_mae: 2869.1028\n",
      "Epoch 64/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3041.4482 - mae: 3039.8533 - val_loss: 2866.2488 - val_mae: 2864.6472\n",
      "Epoch 65/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3198.1140 - mae: 3196.5134 - val_loss: 2865.8591 - val_mae: 2864.2593\n",
      "Epoch 66/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3317.6211 - mae: 3316.0259 - val_loss: 2853.2241 - val_mae: 2851.6238\n",
      "Epoch 67/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3222.7852 - mae: 3221.1848 - val_loss: 2873.2766 - val_mae: 2871.6677\n",
      "Epoch 68/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3241.6960 - mae: 3240.0933 - val_loss: 2863.9177 - val_mae: 2862.3240\n",
      "Epoch 69/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3272.8142 - mae: 3271.2161 - val_loss: 2864.6785 - val_mae: 2863.0808\n",
      "Epoch 70/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3139.7375 - mae: 3138.1392 - val_loss: 2880.0579 - val_mae: 2878.4431\n",
      "Epoch 71/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3012.7524 - mae: 3011.1458 - val_loss: 2852.6538 - val_mae: 2851.0522\n",
      "Epoch 72/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3096.0747 - mae: 3094.4724 - val_loss: 2857.1536 - val_mae: 2855.5540\n",
      "Epoch 73/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3360.3923 - mae: 3358.7839 - val_loss: 2863.3403 - val_mae: 2861.7412\n",
      "Epoch 74/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3092.8660 - mae: 3091.2627 - val_loss: 2858.5281 - val_mae: 2856.9136\n",
      "Epoch 75/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3240.5610 - mae: 3238.9529 - val_loss: 2902.6179 - val_mae: 2901.0212\n",
      "Epoch 76/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3157.5959 - mae: 3155.9900 - val_loss: 2866.7432 - val_mae: 2865.1318\n",
      "Epoch 77/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3330.3914 - mae: 3328.7781 - val_loss: 2853.4155 - val_mae: 2851.8005\n",
      "Epoch 78/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3498.6489 - mae: 3497.0405 - val_loss: 2853.3704 - val_mae: 2851.7666\n",
      "Epoch 79/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3240.1912 - mae: 3238.5884 - val_loss: 2869.5586 - val_mae: 2867.9583\n",
      "Epoch 80/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3154.5825 - mae: 3152.9741 - val_loss: 2865.0337 - val_mae: 2863.4216\n",
      "Epoch 81/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3242.6758 - mae: 3241.0659 - val_loss: 2862.9983 - val_mae: 2861.3950\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, validation_data=(X_val_scaled, y_val), \n",
    "                    epochs=300, batch_size=32, callbacks=[early_stopping], verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7da5e828-c870-43da-aead-32831fa02de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2944.5681 - mae: 2942.9663\n",
      "Validation Mean Absolute Error: 2851.05\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "val_loss, val_mae = model.evaluate(X_val_scaled, y_val)\n",
    "print(f'Validation Mean Absolute Error: {val_mae:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3b993e3-2657-45cd-9f6b-9b5589fc01fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_predict = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fba111c-f00a-4be9-8320-db73f9f37a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            price\n",
      "0    18939.982422\n",
      "1    16674.611328\n",
      "2    18539.238281\n",
      "3    15263.683594\n",
      "4     7102.289062\n",
      "..            ...\n",
      "406  22212.279297\n",
      "407  12685.937500\n",
      "408   9902.892578\n",
      "409  17383.431641\n",
      "410  12656.580078\n",
      "\n",
      "[411 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for the predictions\n",
    "df_predictions = pd.DataFrame(y_predict, columns=['price'])\n",
    "\n",
    "# Display predictions\n",
    "print(df_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95a39c87-aa35-495b-a7da-67d7d04ce902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18939.982422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16674.611328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18539.238281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15263.683594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7102.289062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>406</td>\n",
       "      <td>22212.279297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>407</td>\n",
       "      <td>12685.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>408</td>\n",
       "      <td>9902.892578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>409</td>\n",
       "      <td>17383.431641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>12656.580078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id         price\n",
       "0      0  18939.982422\n",
       "1      1  16674.611328\n",
       "2      2  18539.238281\n",
       "3      3  15263.683594\n",
       "4      4   7102.289062\n",
       "..   ...           ...\n",
       "406  406  22212.279297\n",
       "407  407  12685.937500\n",
       "408  408   9902.892578\n",
       "409  409  17383.431641\n",
       "410  410  12656.580078\n",
       "\n",
       "[411 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([test_df['Id'], df_predictions], axis=1)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b436027-155e-4634-b427-607deb975470",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('zab.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c174da83-dae9-45d0-a7f6-f345cf6911e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
